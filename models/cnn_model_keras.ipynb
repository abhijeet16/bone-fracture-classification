{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 10:54:26.794907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 10:54:28.708367: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:28.708403: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-05 10:54:28.872987: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-05 10:54:32.661670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:32.662210: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:32.662220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import numpy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2219 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 10:54:43.146967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:54:43.147450: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:43.148404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:43.149126: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:43.150025: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:43.151019: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:43.152189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:43.153253: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:43.154109: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-05 10:54:43.154142: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-05 10:54:43.163088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 741 files belonging to 2 classes.\n",
      "Found 731 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define image size\n",
    "image_size = (224, 224)\n",
    "\n",
    "# import train data\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory='./data/train',\n",
    "    seed = 1337,\n",
    "    batch_size=64,\n",
    "    image_size=image_size)\n",
    "\n",
    "# import valid data\n",
    "validation_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory='./data/valid',\n",
    "    seed = 1337,\n",
    "    batch_size=64,\n",
    "    image_size=image_size)\n",
    "\n",
    "# import test data\n",
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory='./data/test',\n",
    "    seed = 1337,\n",
    "    batch_size=64,\n",
    "    image_size=(image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmented_train_ds = train_ds.map(\n",
    "    lambda img, label: (data_augmentation(img, training = True), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 224, 224, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 112, 112, 12  3584        ['rescaling[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 112, 112, 12  512        ['conv2d[0][0]']                 \n",
      " alization)                     8)                                                                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 112, 112, 12  0           ['batch_normalization[0][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 112, 112, 12  0           ['activation[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " separable_conv2d (SeparableCon  (None, 112, 112, 25  34176      ['activation_1[0][0]']           \n",
      " v2D)                           6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 112, 112, 25  1024       ['separable_conv2d[0][0]']       \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 112, 112, 25  0           ['batch_normalization_1[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " separable_conv2d_1 (SeparableC  (None, 112, 112, 25  68096      ['activation_2[0][0]']           \n",
      " onv2D)                         6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 112, 112, 25  1024       ['separable_conv2d_1[0][0]']     \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 56, 56, 256)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 56, 56, 256)  33024       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 56, 56, 256)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 56, 56, 256)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " separable_conv2d_2 (SeparableC  (None, 56, 56, 512)  133888     ['activation_3[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 56, 56, 512)  2048       ['separable_conv2d_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 512)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_3 (SeparableC  (None, 56, 56, 512)  267264     ['activation_4[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 512)  2048       ['separable_conv2d_3[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 512)  0          ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 512)  131584      ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 28, 28, 512)  0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 28, 28, 512)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " separable_conv2d_4 (SeparableC  (None, 28, 28, 728)  378072     ['activation_5[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 28, 728)  2912       ['separable_conv2d_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 28, 28, 728)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " separable_conv2d_5 (SeparableC  (None, 28, 28, 728)  537264     ['activation_6[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 728)  2912       ['separable_conv2d_5[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 728)  0          ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 14, 14, 728)  373464      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 14, 14, 728)  0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " separable_conv2d_6 (SeparableC  (None, 14, 14, 1024  753048     ['add_2[0][0]']                  \n",
      " onv2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 14, 14, 1024  4096       ['separable_conv2d_6[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 14, 14, 1024  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1024)        0           ['activation_7[0][0]']           \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            1025        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,731,065\n",
      "Trainable params: 2,722,777\n",
      "Non-trainable params: 8,288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = build_model(input_shape=image_size + (3,), num_classes=2)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 472s 13s/step - loss: 0.5495 - accuracy: 0.7850 - val_loss: 0.6326 - val_accuracy: 0.8003\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 458s 13s/step - loss: 0.5153 - accuracy: 0.7981 - val_loss: 0.5837 - val_accuracy: 0.8003\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 460s 13s/step - loss: 0.5173 - accuracy: 0.7977 - val_loss: 0.5515 - val_accuracy: 0.8003\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 461s 13s/step - loss: 0.5129 - accuracy: 0.7963 - val_loss: 0.5303 - val_accuracy: 0.8003\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 472s 13s/step - loss: 0.5081 - accuracy: 0.7954 - val_loss: 0.5091 - val_accuracy: 0.8003\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 461s 13s/step - loss: 0.5181 - accuracy: 0.7909 - val_loss: 0.5020 - val_accuracy: 0.8003\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 460s 13s/step - loss: 0.4984 - accuracy: 0.7990 - val_loss: 0.5002 - val_accuracy: 0.8003\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 461s 13s/step - loss: 0.5087 - accuracy: 0.7954 - val_loss: 0.5039 - val_accuracy: 0.8003\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.7959 "
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "epochs = 20\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 40s 3s/step - loss: 0.5028 - accuracy: 0.8044\n",
      "test loss, test acc: [0.5027822256088257, 0.804377555847168]\n"
     ]
    }
   ],
   "source": [
    "#  Evaluate Model\n",
    "score = model.evaluate(test_ds, batch_size=64)\n",
    "print(\"test loss, test acc:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 731 images belonging to 2 classes.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AFF       0.00      0.00      0.00       143\n",
      "     CONTROL       0.80      1.00      0.89       588\n",
      "\n",
      "    accuracy                           0.80       731\n",
      "   macro avg       0.40      0.50      0.45       731\n",
      "weighted avg       0.65      0.80      0.72       731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import test data\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('./data/test',\n",
    "                                           target_size = (224,224),\n",
    "                                           batch_size = 64,\n",
    "                                           shuffle=False,\n",
    "                                           class_mode ='binary')\n",
    "\n",
    "test_steps_per_epoch = numpy.math.ceil(test_set.samples / test_set.batch_size)\n",
    "\n",
    "# Collect predictions\n",
    "predictions = model.predict_generator(test_set, steps=test_steps_per_epoch)\n",
    "predictions = numpy.hstack(predictions)\n",
    "predictions = [round(x) for x in predictions]\n",
    "\n",
    "\n",
    "# collect true labels\n",
    "true_classes = test_set.classes\n",
    "\n",
    "# Collect Class labels\n",
    "class_labels = list(test_set.class_indices.keys())\n",
    "\n",
    "# Print Classification report\n",
    "report = classification_report(true_classes, predictions, target_names=class_labels)\n",
    "print(report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print Confusion Matrix\n",
    "cf_matrix = confusion_matrix(true_classes, predictions)\n",
    "sns.heatmap(cf_matrix, annot=True, cmap=\"crest\", fmt=\".1f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('rproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 29 2022, 02:18:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e946d31130eb1bc4e37f352c533ccb42f63d92b792041f91bcc2710872c3a96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
